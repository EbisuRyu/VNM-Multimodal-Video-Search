{"cells":[{"cell_type":"markdown","metadata":{},"source":["#### **Import Libraries**"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["!pip install -q -r requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["d:\\HCMAI-AnniVators\\extra\n"]},{"name":"stderr","output_type":"stream","text":["Cloning into 'mmocr'...\n"]}],"source":["%cd ../../extra\n","!git clone https://github.com/open-mmlab/mmocr.git"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["d:\\HCMAI-AnniVators\\extra\\mmocr\n"]},{"name":"stderr","output_type":"stream","text":["  DEPRECATION: Legacy editable install of mmocr==1.0.1 from file:///D:/HCMAI-AnniVators/extra/mmocr (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\n"]}],"source":["%cd mmocr\n","!pip install -qe ."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"TimI1k8No44g"},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Miniconda3\\envs\\aic-env\\lib\\site-packages\\mmengine\\optim\\optimizer\\zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n","  from torch.distributed.optim import \\\n"]}],"source":["import os\n","import cv2\n","import json\n","import torch\n","import string\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","from underthesea import text_normalize\n","from vietocr.tool.config import Cfg\n","from vietocr.tool.predictor import Predictor\n","from mmocr.apis import MMOCRInferencer"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"O2D2dGT0o8TO"},"outputs":[{"name":"stdout","output_type":"stream","text":["d:\\HCMAI-AnniVators\\dataset\n"]}],"source":["%cd ../../dataset"]},{"cell_type":"markdown","metadata":{},"source":["#### **Parsing Data Path**"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"QqKxg46jpD1W"},"outputs":[],"source":["def parse_data_path(feature_dir='./distilled_keyframe'):\n","    all_feature_paths = dict()\n","    for feature_part in sorted(os.listdir(feature_dir)):\n","        all_feature_paths[feature_part] = dict()\n","    for feature_part in sorted(all_feature_paths.keys()):\n","        feature_part_path = f'{feature_dir}/{feature_part}'\n","        feature_paths = sorted(os.listdir(feature_part_path))\n","        feature_ids = [feature_path.split('.')[0] for feature_path in feature_paths]\n","        for feature_id, feature_path in zip(feature_ids, feature_paths):\n","            feature_path_full = f'{feature_part_path}/{feature_path}'\n","            all_feature_paths[feature_part][feature_id] = feature_path_full\n","    return all_feature_paths"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["keyframe_dir='./distilled_keyframe'\n","all_keyframe_paths = parse_data_path(feature_dir=keyframe_dir)"]},{"cell_type":"markdown","metadata":{},"source":["#### **Function Definition**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ZO502jmepWVB"},"outputs":[],"source":["def sorted_by_id(keyframe_paths):\n","    id_path_keyframes = []\n","    for keyframe_path in keyframe_paths:\n","        keyframe_filename = keyframe_path.split('/')[-1]\n","        keyframe_id = int(keyframe_filename.split('.')[0])\n","        id_path_keyframes.append((keyframe_id, keyframe_path))\n","    sorted_id_path_keyframes = sorted(id_path_keyframes, key=lambda id_path: id_path[0])\n","    return [id_path[1] for id_path in sorted_id_path_keyframes]\n","\n","def text_processing(text):\n","    processed_text = text.lower()\n","    processed_text = text_normalize(processed_text)\n","    processed_text = processed_text.translate(str.maketrans('', '', string.punctuation))\n","    return processed_text\n","\n","def load_image(image_path):\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Không thể đọc ảnh từ đường dẫn: {image_path}\")\n","    return image\n","\n","def extract_polygons(result_detect):\n","    if not result_detect or 'predictions' not in result_detect or not result_detect['predictions']:\n","        return []\n","    pred = result_detect['predictions'][0]\n","    return pred.get('det_polygons', [])\n","\n","def get_top_left_corner(polygon):\n","    polygon = np.array(polygon).reshape(-1, 2)\n","    x_min = np.min(polygon[:, 0])\n","    y_min = np.min(polygon[:, 1])\n","    return x_min, y_min\n","\n","def sort_polygons(polygons):\n","    polygons_with_top_left = [(polygon, *get_top_left_corner(polygon)) for polygon in polygons]\n","    polygons_sorted = sorted(polygons_with_top_left, key=lambda x: (x[2], x[1]))\n","    sorted_polygons = [item[0] for item in polygons_sorted]\n","    return sorted_polygons\n","\n","def crop_polygon(image, polygon, y_threshold):\n","    polygon = np.array(polygon).reshape(-1, 2)\n","    # Find minimum and maximum x, y coordinates\n","    x_min, y_min = np.min(polygon, axis=0)\n","    x_max, y_max = np.max(polygon, axis=0)\n","\n","    if float((y_max-y_threshold)) / (y_max-y_min) > 0.5:\n","        return None\n","\n","    # Ensure the coordinates are within the image boundaries\n","    x_min, y_min = max(0, int(x_min)), max(0, int(y_min))\n","    x_max, y_max = min(image.shape[1], int(x_max)), min(image.shape[0], int(y_max))\n","    if x_min >= x_max or y_min >= y_max:\n","        return None\n","    return image[int(y_min):int(y_max), int(x_min):int(x_max)]\n","\n","def recognize_text(cropped_img):\n","    if cropped_img is None:\n","        return \"\"\n","    cropped_img_pil = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))\n","    text_vietocr = vietocr_predictor.predict(cropped_img_pil)\n","    return text_vietocr.strip()\n","\n","def det_and_reg(image_path, y_threshold=650):\n","    image = load_image(image_path)\n","    if image is None:\n","        return \"\"\n","\n","    result_detect = mmocr_infer(image_path, return_vis=False)\n","    polygons = extract_polygons(result_detect)\n","    sorted_polygons = sort_polygons(polygons)\n","\n","    text_of_image = \"\"\n","\n","    for polygon in sorted_polygons:\n","        if len(polygon) == 0:\n","            continue\n","\n","        cropped_image = crop_polygon(image, polygon, y_threshold)\n","        if cropped_image is None:\n","            continue\n","\n","        text = recognize_text(cropped_image)\n","        if text:\n","            text_of_image += \" \" + text\n","\n","    return text_processing(text_of_image.strip())\n","\n","def write_json_file(json_data, file_path):\n","    with open(file_path, 'w') as f:\n","        json.dump(json_data, f, ensure_ascii=False, indent=4)"]},{"cell_type":"markdown","metadata":{},"source":["#### **Inference**"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"KLpobjp6piSZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loads checkpoint by http backend from path: https://download.openmmlab.com/mmocr/textdet/drrg/drrg_resnet50_fpn-unet_1200e_ctw1500/drrg_resnet50_fpn-unet_1200e_ctw1500_20220827_105233-d5c702dd.pth\n","The model and loaded state dict do not match exactly\n","\n","unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n","\n","08/25 09:10:36 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmocr\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmocr\" is a correct scope, or whether the registry is initialized.\n"]},{"name":"stderr","output_type":"stream","text":["d:\\Miniconda3\\envs\\aic-env\\lib\\site-packages\\mmengine\\visualization\\visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n","  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n","d:\\Miniconda3\\envs\\aic-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]},{"name":"stdout","output_type":"stream","text":["Model weight C:\\Users\\LENOVO~1\\AppData\\Local\\Temp\\vgg_transformer.pth exsits. Ignore download!\n"]},{"name":"stderr","output_type":"stream","text":["d:\\Miniconda3\\envs\\aic-env\\lib\\site-packages\\vietocr\\tool\\predictor.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(weights, map_location=torch.device(device)))\n"]}],"source":["# Initialize the MMOCR inferencer\n","mmocr_infer = MMOCRInferencer(det='drrg')\n","\n","# VietOCR configuration\n","config = Cfg.load_config_from_name('vgg_transformer')\n","config['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n","config['cnn']['pretrained']=False\n","vietocr_predictor = Predictor(config)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"pH-yS84pppD-"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/30 [00:00<?, ?it/s]"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4165229ef1a74787ab5243b6181693b9","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{},"output_type":"display_data"}],"source":["save_dir = './filter/ocr'\n","os.makedirs(save_dir, exist_ok=True)\n","\n","for video_part, video_path_dict in all_keyframe_paths.items():\n","    full_save_dir = os.path.join(save_dir, video_part)\n","    os.makedirs(full_save_dir, exist_ok=True)\n","    video_ids = sorted(video_path_dict.keys())\n","    for video_id in tqdm(video_ids):\n","        json_records = []\n","        video_id_path = video_path_dict[video_id]\n","        keyframe_image_paths = [video_id_path + '/' + keyframe_image_path for keyframe_image_path in os.listdir(video_id_path)]\n","        sorted_keyframe_image_paths = sorted_by_id(keyframe_image_paths)\n","        for keyframe_image_path in sorted_keyframe_image_paths:\n","            frame_ocr_result = det_and_reg(keyframe_image_path)\n","            record = {\n","                \"L\": video_part,\n","                \"V\": video_id,\n","                \"ID_FRAME\": os.path.basename(keyframe_image_path).split('.')[0],  # Giả định rằng ID_FRAME là tên file ~hông có đuôi\n","                \"TEXT\": frame_ocr_result\n","            }\n","            json_records.append(record)\n","        write_json_file(json_records, os.path.join(full_save_dir, f'{video_id}.json'))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNrIVx8pIed9LyBYPlTDHG6","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":0}
