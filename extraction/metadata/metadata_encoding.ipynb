{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LONG\\anaconda3\\envs\\aic2024-env-new\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy\n",
    "import pickle\n",
    "import json\n",
    "import bm25s\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\AIC2024\\dataset\n"
     ]
    }
   ],
   "source": [
    "%cd D:/AIC2024/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_by_id(keyframe_paths):\n",
    "    id_path_keyframes = []\n",
    "    for keyframe_path in keyframe_paths:\n",
    "        keyframe_filename = keyframe_path.split('/')[-1]\n",
    "        keyframe_id = int(keyframe_filename.split('.')[0])\n",
    "        id_path_keyframes.append((keyframe_id, keyframe_path))\n",
    "    sorted_id_path_keyframes = sorted(id_path_keyframes, key=lambda id_path: id_path[0])\n",
    "    return [id_path[1] for id_path in sorted_id_path_keyframes]\n",
    "\n",
    "def sort_dict_by_filename(feature_dict):\n",
    "    # Sort the dictionary based on the extracted numeric part of the filenames\n",
    "    sorted_keyframe_paths = sorted_by_id(list(feature_dict.keys()))\n",
    "    return {keyframe_path: feature_dict[keyframe_path] for keyframe_path in sorted_keyframe_paths}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Metadata Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataEncoder:\n",
    "    def __init__(self, metadata_dirs, all_datatype, ngram_range=(1, 1)):\n",
    "        self.metadata_dirs = metadata_dirs\n",
    "        self.all_datatype = all_datatype\n",
    "        self.ngram_range = ngram_range\n",
    "\n",
    "    def load_context(self, metadata_dir, data_type):\n",
    "        # Initialize context and data_paths\n",
    "        feature_data_paths = []\n",
    "        # Get sorted list of all directories matching the metadata_path\n",
    "        part_data_dirs = sorted([metadata_dir + '/' + video_part for video_part in os.listdir(metadata_dir)])\n",
    "        # Iterate through each directory and gather all .txt file paths\n",
    "        for part_data_dir in part_data_dirs:\n",
    "            video_data_paths = sorted([part_data_dir + '/' + video_id for video_id in os.listdir(part_data_dir)])\n",
    "            feature_data_paths.extend(video_data_paths)\n",
    "        \n",
    "        keyframe_paths, metadata_features = [], []\n",
    "        for fearure_data_path in feature_data_paths:\n",
    "            with open(fearure_data_path, 'r') as f:\n",
    "                metadata_dict = json.load(f)\n",
    "                sorted_metadata_dict = sort_dict_by_filename(metadata_dict)\n",
    "                keyframe_paths.extend(list(sorted_metadata_dict.keys()))\n",
    "                metadata_features.extend([metadata_feature[data_type] for metadata_feature in sorted_metadata_dict.values()])\n",
    "        \n",
    "        id2image_fps = {index : path for index, path in enumerate(keyframe_paths)}\n",
    "        return id2image_fps, metadata_features\n",
    "\n",
    "    def save_context_tfidf(self, save_path, data_type):\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        save_context_matrix_path = os.path.join(save_path, f'sparse_context_matrix_{data_type}.npz')\n",
    "        save_transform_path = os.path.join(save_path, f'transform_{data_type}.pkl')\n",
    "        json_file_path = os.path.join(save_path, f'id2image_fps_{data_type}.json')\n",
    "\n",
    "        scipy.sparse.save_npz(save_context_matrix_path, self.context_matrix)\n",
    "        with open(save_transform_path, 'wb') as f:\n",
    "            pickle.dump(self.transform, f)\n",
    "        with open(json_file_path, \"w\") as file:\n",
    "            json.dump(self.id2image_fps, file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    def save_context_bm25(self, save_path, data_type):\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        self.transform.save(save_path, corpus=self.metadata_features)\n",
    "        json_file_path = os.path.join(save_path, f'id2image_fps_{data_type}.json')\n",
    "        with open(json_file_path, \"w\") as file:\n",
    "            json.dump(self.id2image_fps, file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    def extract_metadata_tfidf(self, data_type):\n",
    "        metadata_dir = self.metadata_dirs[data_type]\n",
    "        self.id2image_fps, self.metadata_features = self.load_context(metadata_dir, data_type)\n",
    "        self.transform = TfidfVectorizer(input = 'content', ngram_range = (1, 1), token_pattern=r\"(?u)\\b[\\w\\d]+\\b\")\n",
    "        self.context_matrix = self.transform.fit_transform(self.metadata_features).tocsr()\n",
    "    \n",
    "    def extract_metadata_bm25(self, data_type):\n",
    "        metadata_dir = self.metadata_dirs[data_type]\n",
    "        self.id2image_fps, self.metadata_features = self.load_context(metadata_dir, data_type)\n",
    "        tokenized_context = bm25s.tokenize(self.metadata_features)\n",
    "        self.transform = bm25s.BM25(method=\"lucene\")\n",
    "        self.transform.index(tokenized_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Metadata Paths Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_path = './metadata/object/features'\n",
    "color_path = './metadata/color/features'\n",
    "metadata_dirs = {\n",
    "    'object_bbox': object_path,\n",
    "    'object_class': object_path,\n",
    "    'object_number': object_path,\n",
    "    'color_bbox': color_path,\n",
    "    'color_class': color_path,\n",
    "}\n",
    "all_datatype = ['object_bbox', 'object_class', 'object_number', 'color_bbox', 'color_class']\n",
    "context_encoder = MetadataEncoder(metadata_dirs=metadata_dirs, all_datatype=all_datatype, ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Encoding using TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_types = ['object_bbox', 'object_class', 'object_number']\n",
    "for metadata_type in metadata_types:\n",
    "    save_path = f'./metadata/object/dict/tf-idf/{metadata_type}'\n",
    "    context_encoder.extract_metadata_tfidf(metadata_type)\n",
    "    context_encoder.save_context_tfidf(save_path, metadata_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_types = ['color_bbox', 'color_class']\n",
    "for metadata_type in metadata_types:\n",
    "    save_path = f'./metadata/color/dict/tf-idf/{metadata_type}'\n",
    "    context_encoder.extract_metadata_tfidf(metadata_type)\n",
    "    context_encoder.save_context_tfidf(save_path, metadata_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Encoding using BM25**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding newlines for mmindex: 100%|██████████| 50.1M/50.1M [00:04<00:00, 11.8MB/s]\n",
      "Finding newlines for mmindex: 100%|██████████| 9.05M/9.05M [00:05<00:00, 1.67MB/s]\n",
      "Finding newlines for mmindex: 100%|██████████| 6.52M/6.52M [00:04<00:00, 1.47MB/s]\n"
     ]
    }
   ],
   "source": [
    "metadata_types = ['object_bbox', 'object_class', 'object_number']\n",
    "for metadata_type in metadata_types:\n",
    "    save_path = f'./metadata/object/dict/bm25/{metadata_type}'\n",
    "    context_encoder.extract_metadata_bm25(metadata_type)\n",
    "    context_encoder.save_context_bm25(save_path, metadata_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding newlines for mmindex: 100%|██████████| 210M/210M [00:05<00:00, 41.0MB/s]   \n",
      "Finding newlines for mmindex: 100%|██████████| 156M/156M [00:04<00:00, 38.7MB/s] \n"
     ]
    }
   ],
   "source": [
    "metadata_types = ['color_bbox', 'color_class']\n",
    "for metadata_type in metadata_types:\n",
    "    save_path = f'./metadata/color/dict/bm25/{metadata_type}'\n",
    "    context_encoder.extract_metadata_bm25(metadata_type)\n",
    "    context_encoder.save_context_bm25(save_path, metadata_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aic2024-env-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
