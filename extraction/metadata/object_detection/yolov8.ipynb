{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "from torchvision.ops import box_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd D:/AIC2024/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parsing Data Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_path(feature_dir='./keyframe'):\n",
    "    all_feature_paths = dict()\n",
    "    for feature_part in sorted(os.listdir(feature_dir)):\n",
    "        all_feature_paths[feature_part] = dict()\n",
    "    for feature_part in sorted(all_feature_paths.keys()):\n",
    "        feature_part_path = f'{feature_dir}/{feature_part}'\n",
    "        feature_paths = sorted(os.listdir(feature_part_path))\n",
    "        feature_ids = [feature_path.split('.')[0] for feature_path in feature_paths]\n",
    "        for feature_id, feature_path in zip(feature_ids, feature_paths):\n",
    "            feature_path_full = f'{feature_part_path}/{feature_path}'\n",
    "            all_feature_paths[feature_part][feature_id] = feature_path_full\n",
    "    return all_feature_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyframe_dir='./distilled_keyframe'\n",
    "all_keyframe_paths = parse_data_path(feature_dir=keyframe_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Object Textual Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_object_classes = [\n",
    "    # Phương tiện giao thông\n",
    "    \"bicycle\", \"car\", \"motorcycle\", \"airplane\",\n",
    "    \"bus\", \"train\", \"truck\", \"boat\",\n",
    "\n",
    "    # Động vật\n",
    "    \"person\", \"bird\", \"cat\", \"dog\",\n",
    "    \"horse\", \"sheep\", \"cow\", \"elephant\",\n",
    "    \"bear\", \"zebra\", \"giraffe\",\n",
    "\n",
    "    # Đồ dùng cá nhân\n",
    "    \"backpack\", \"umbrella\", \"handbag\",\n",
    "    \"suitcase\", \"book\",\n",
    "\n",
    "    # Đồ dùng thể thao\n",
    "    \"kite\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "    \"baseball bat\", \"baseball glove\", \"skateboard\",\n",
    "    \"surfboard\", \"tennis racket\",\n",
    "\n",
    "    # Dụng cụ ăn uống\n",
    "    \"bottle\", \"wine glass\", \"cup\", \"fork\",\n",
    "    \"knife\", \"spoon\", \"bowl\",\n",
    "\n",
    "    # Hoa quả\n",
    "    \"banana\", \"apple\", \"sandwich\", \"orange\",\n",
    "    \"broccoli\", \"carrot\", \"hot dog\", \"pizza\",\n",
    "    \"donut\", \"cake\",\n",
    "\n",
    "    # Nội thất\n",
    "    \"chair\", \"couch\", \"potted plant\", \"bed\",\n",
    "    \"dining table\", \"toilet\", \"clock\", \"vase\",\n",
    "\n",
    "    # Thiết bị điện tử\n",
    "    \"tv\", \"laptop\", \"mouse\", \"remote\",\n",
    "    \"keyboard\", \"cell phone\", \"microwave\",\n",
    "    \"oven\", \"toaster\", \"refrigerator\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectTextualEncoder:\n",
    "\n",
    "    def __init__(self, row_str=None, col_str=None, object_classes=None):\n",
    "        self.row_str = row_str or ['0', '1', '2', '3', '4', '5', '6']\n",
    "        self.col_str = col_str or ['a', 'b', 'c', 'd', 'e', 'f', 'g']\n",
    "        self.object_classes = object_classes or default_object_classes\n",
    "        \n",
    "        self.x_pts = np.linspace(0, 1, len(self.row_str) + 1)\n",
    "        self.y_pts = np.linspace(0, 1, len(self.col_str) + 1)\n",
    "        \n",
    "        self.grid_bboxes, self.grid_labels = self.initialize_grid_bboxes()\n",
    "\n",
    "    def initialize_grid_bboxes(self):\n",
    "        grid_bboxes, grid_labels = [], []\n",
    "        for row, row_label in enumerate(self.row_str):\n",
    "            for col, col_label in enumerate(self.col_str):\n",
    "                grid_bboxes.append([self.x_pts[col], self.y_pts[row], self.x_pts[col + 1], self.y_pts[row + 1]])\n",
    "                grid_labels.append(f\"{col_label}{row_label}\")\n",
    "        return np.array(grid_bboxes), grid_labels\n",
    "\n",
    "    def visual_grid_bboxes(self, image):\n",
    "        grid_image = image.copy() if image is not None else np.zeros((210, 210, 3), dtype=np.uint8)\n",
    "        h, w = grid_image.shape[:2]\n",
    "\n",
    "        for bbox, label in zip(self.grid_bboxes, self.grid_labels):\n",
    "            x_start, y_start, x_end, y_end = (bbox * [w, h, w, h]).astype(int)\n",
    "            org = (int(x_start + (x_end - x_start) / 2) - 10, int(y_start + (y_end - y_start) / 2))\n",
    "            cv2.putText(grid_image, label, org, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            cv2.rectangle(grid_image, (x_start, y_start), (x_end, y_end), (255, 255, 0), 1)\n",
    "\n",
    "        plt.imshow(cv2.cvtColor(grid_image, cv2.COLOR_RGB2BGR))\n",
    "        plt.show()\n",
    "    \n",
    "    def scale_bboxes(self, bboxes, h, w):\n",
    "        scale_matrix = np.array([[w, 0, 0, 0], [0, h, 0, 0], [0, 0, w, 0], [0, 0, 0, h]])\n",
    "        return bboxes @ scale_matrix\n",
    "\n",
    "    def textual_encoding_object_bboxes(self, image, bboxes, labels):\n",
    "        h, w = image.shape[:2]\n",
    "        scaled_grid_bboxes = self.scale_bboxes(self.grid_bboxes, h, w)\n",
    "        scaled_bboxes = self.scale_bboxes(bboxes, h, w)\n",
    "\n",
    "        iou_scores = box_iou(torch.as_tensor(scaled_bboxes), torch.as_tensor(scaled_grid_bboxes)).numpy()\n",
    "        bboxes_ids, grid_bboxes_ids = np.nonzero(iou_scores)\n",
    "\n",
    "        return ' '.join(\n",
    "            sorted([self.grid_labels[grid_bbox_id] + labels[bbox_id].replace(\" \", \"\")\n",
    "            for bbox_id, grid_bbox_id in zip(bboxes_ids, grid_bboxes_ids)])\n",
    "        )\n",
    "    \n",
    "    def textual_encoding_object_numbers(self, labels):\n",
    "        unique_labels = sorted(set(labels))\n",
    "        return ' '.join(\n",
    "            sorted([label.replace(\" \", \"\") + str(labels.count(label))\n",
    "            for label in unique_labels])\n",
    "        )\n",
    "        \n",
    "    def textual_encoding_object_classes(self, labels):\n",
    "        object_classes = []\n",
    "        unique_labels = sorted(set(labels))\n",
    "        for unique_label in unique_labels:\n",
    "            count = labels.count(unique_label)\n",
    "            object_classes.extend([(unique_label + str(i)).replace(\" \", \"\") for i in range(1, count + 1)])\n",
    "        return ' '.join(sorted(object_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **YOLOv8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd D:/AIC2024/extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YOLO('yolov8x.pt')  # pretrained YOLOv8n model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd D:/AIC2024/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Object Bounding Box, Object Number and Object Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_processing(label):\n",
    "    return '_'.join(label.split(' '))\n",
    "\n",
    "def filter_detections(results, object_encoder, model):\n",
    "    \"\"\"Lọc các kết quả phát hiện theo object_classes của object_encoder.\"\"\"\n",
    "    filtered_data = []\n",
    "    for result in results:\n",
    "        bboxes = result.boxes.xyxyn.cpu().numpy().copy()\n",
    "        label_ids = result.boxes.cls.cpu().numpy().copy()\n",
    "        labels = [model.names[index] for index in label_ids]\n",
    "\n",
    "        # Lọc theo object_classes\n",
    "        filtered_bboxes = [bbox for bbox, label in zip(bboxes, labels) if label in object_encoder.object_classes]\n",
    "        filtered_labels = [label_processing(label) for label in labels if label in object_encoder.object_classes]\n",
    "\n",
    "        filtered_data.append((filtered_bboxes, filtered_labels))\n",
    "    return filtered_data\n",
    "\n",
    "def encode_metadata(image, bboxes, labels, object_encoder):\n",
    "    \"\"\"Mã hóa và trả về metadata cho mỗi keyframe.\"\"\"\n",
    "    encoded_class = object_encoder.textual_encoding_object_classes(labels) if len(labels) > 0 else ''\n",
    "    encoded_bbox = object_encoder.textual_encoding_object_bboxes(image, bboxes, labels) if len(labels) > 0 else ''\n",
    "    encoded_number = object_encoder.textual_encoding_object_numbers(labels) if len(labels) > 0 else ''\n",
    "    return {\n",
    "        'object_bbox': encoded_bbox,\n",
    "        'object_class': encoded_class,\n",
    "        'object_number': encoded_number\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_text_file(text, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(text)\n",
    "\n",
    "def write_json_file(json_data, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def sorted_by_id(keyframe_paths):\n",
    "    id_path_keyframes = []\n",
    "    for keyframe_path in keyframe_paths:\n",
    "        keyframe_filename = keyframe_path.split('/')[-1]\n",
    "        keyframe_id = int(keyframe_filename.split('.')[0])\n",
    "        id_path_keyframes.append((keyframe_id, keyframe_path))\n",
    "    sorted_id_path_keyframes = sorted(id_path_keyframes, key=lambda id_path: id_path[0])\n",
    "    return [id_path[1] for id_path in sorted_id_path_keyframes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình các thông số\n",
    "save_dir = './metadata/object/features'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "batch_size = 4\n",
    "confidence = 0.6\n",
    "object_encoder = ObjectTextualEncoder()\n",
    "# Duyệt qua các video và keyframe\n",
    "for video_part, video_path_dict in all_keyframe_paths.items():\n",
    "    full_save_dir = save_dir + '/' + video_part\n",
    "    os.makedirs(full_save_dir, exist_ok=True)\n",
    "    \n",
    "    for video_id in tqdm(video_path_dict.keys(), desc=f'Encoding Part {video_part}'):\n",
    "        video_metadata = {}\n",
    "        keyframe_paths = sorted_by_id(\n",
    "            video_path_dict[video_id] + '/' + keyframe \n",
    "            for keyframe in os.listdir(video_path_dict[video_id])\n",
    "        )\n",
    "\n",
    "        # Xử lý các batch keyframe\n",
    "        for i in range(0, len(keyframe_paths), batch_size):\n",
    "            batch_paths = keyframe_paths[i:i + batch_size]\n",
    "            results = model(batch_paths, conf=confidence, device=device, verbose=False)\n",
    "\n",
    "            # Lọc và mã hóa metadata\n",
    "            filtered_results = filter_detections(results, object_encoder, model)\n",
    "            for keyframe_path, (bboxes, labels) in zip(batch_paths, filtered_results):\n",
    "                image = cv2.imread(keyframe_path)\n",
    "                video_metadata[keyframe_path] = encode_metadata(image, bboxes, labels, object_encoder)\n",
    "\n",
    "        # Lưu metadata vào file JSON\n",
    "        write_json_file(video_metadata, os.path.join(full_save_dir, f'{video_id}.json'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aic2024-env-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
