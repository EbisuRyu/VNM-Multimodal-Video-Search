{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parsing Data Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_path(feature_dir):\n",
    "    all_feature_paths = dict()\n",
    "    for feature_part in sorted(os.listdir(feature_dir)):\n",
    "        all_feature_paths[feature_part] = dict()\n",
    "    for feature_part in sorted(all_feature_paths.keys()):\n",
    "        feature_part_path = f'{feature_dir}/{feature_part}'\n",
    "        feature_paths = sorted(os.listdir(feature_part_path))\n",
    "        feature_ids = [feature_path.split('.')[0] for feature_path in feature_paths]\n",
    "        for feature_id, feature_path in zip(feature_ids, feature_paths):\n",
    "            feature_path_full = f'{feature_part_path}/{feature_path}'\n",
    "            all_feature_paths[feature_part][feature_id] = feature_path_full\n",
    "    return all_feature_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_numpy(numpy_data_path):\n",
    "    np_data = np.load(numpy_data_path)\n",
    "    return np_data\n",
    "\n",
    "def reading_json_file(json_path):\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def convert_dict(begin_index, original_dict):\n",
    "    # Convert keys to integers\n",
    "    converted_dict = {begin_index + int(key): value for key, value in original_dict.items()}\n",
    "    return converted_dict\n",
    "\n",
    "def save_bin_file(embeddings, bin_file):\n",
    "    index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, bin_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create CLIP/L14 Bin File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File notebook này để tạo file bin cho các feature mô hình CLIP, BLIP\n",
    "# Muốn tạo folder cho mô hình nào thì cd đến folder chứa feature của mô hình đó trong dataset\n",
    "%cd D:/VNM-Multimodal-Video-Search/dataset/clip/clip-vit-l14-laion400m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clip_paths = parse_data_path(feature_dir='./features')\n",
    "all_id2img_paths = parse_data_path(feature_dir='./id2image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_embeddings = []\n",
    "global_id2image = {}\n",
    "begin_index = 0\n",
    "\n",
    "for clip_part in sorted(all_clip_paths.keys()):\n",
    "    clip_dict = all_clip_paths[clip_part]\n",
    "    id2img_dict = all_id2img_paths[clip_part]\n",
    "    for video_id in tqdm(sorted(clip_dict.keys())):\n",
    "        numpy_data_path = clip_dict[video_id]\n",
    "        id2image_path = id2img_dict[video_id]\n",
    "        numpy_data = load_numpy(numpy_data_path)\n",
    "        id2image_data = reading_json_file(id2image_path)\n",
    "        id2image_data = convert_dict(begin_index, id2image_data)\n",
    "        global_embeddings.append(numpy_data)\n",
    "        global_id2image.update(id2image_data)\n",
    "        begin_index += len(id2image_data.items())\n",
    "global_embeddings = np.concatenate(global_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './dict'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "global_bin_save_path = os.path.join(save_dir, 'l14_laion400m.bin')\n",
    "global_id2img_save_path = os.path.join(save_dir, 'l14_laion400m.json')\n",
    "with open(global_id2img_save_path, 'w') as file:\n",
    "    json.dump(global_id2image, file, ensure_ascii=False, indent=4)\n",
    "save_bin_file(global_embeddings, bin_file=global_bin_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create CLIP/H14 Bin File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File notebook này để tạo file bin cho các feature mô hình CLIP, BLIP\n",
    "# Muốn tạo folder cho mô hình nào thì cd đến folder chứa feature của mô hình đó trong dataset\n",
    "%cd D:/VNM-Multimodal-Video-Search/dataset/clip/clip-vit-h14-laion2b-s32b-b79k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clip_paths = parse_data_path(feature_dir='./features')\n",
    "all_id2img_paths = parse_data_path(feature_dir='./id2image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_embeddings = []\n",
    "global_id2image = {}\n",
    "begin_index = 0\n",
    "\n",
    "for clip_part in sorted(all_clip_paths.keys()):\n",
    "    clip_dict = all_clip_paths[clip_part]\n",
    "    id2img_dict = all_id2img_paths[clip_part]\n",
    "    for video_id in tqdm(sorted(clip_dict.keys())):\n",
    "        numpy_data_path = clip_dict[video_id]\n",
    "        id2image_path = id2img_dict[video_id]\n",
    "        numpy_data = load_numpy(numpy_data_path)\n",
    "        id2image_data = reading_json_file(id2image_path)\n",
    "        id2image_data = convert_dict(begin_index, id2image_data)\n",
    "        global_embeddings.append(numpy_data)\n",
    "        global_id2image.update(id2image_data)\n",
    "        begin_index += len(id2image_data.items())\n",
    "global_embeddings = np.concatenate(global_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './dict'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "global_bin_save_path = os.path.join(save_dir, 'h14_laion2b.bin')\n",
    "global_id2img_save_path = os.path.join(save_dir, 'h14_laion2b.json')\n",
    "with open(global_id2img_save_path, 'w') as file:\n",
    "    json.dump(global_id2image, file, ensure_ascii=False, indent=4)\n",
    "save_bin_file(global_embeddings, bin_file=global_bin_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create CLIP/H14 Bin File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File notebook này để tạo file bin cho các feature mô hình CLIP, BLIP\n",
    "# Muốn tạo folder cho mô hình nào thì cd đến folder chứa feature của mô hình đó trong dataset\n",
    "%cd D:/VNM-Multimodal-Video-Search/dataset/clip/clip-vit-h14-frozen-laion5b-s13b-b90k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clip_paths = parse_data_path(feature_dir='./features')\n",
    "all_id2img_paths = parse_data_path(feature_dir='./id2image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_embeddings = []\n",
    "global_id2image = {}\n",
    "begin_index = 0\n",
    "\n",
    "for clip_part in sorted(all_clip_paths.keys()):\n",
    "    clip_dict = all_clip_paths[clip_part]\n",
    "    id2img_dict = all_id2img_paths[clip_part]\n",
    "    for video_id in tqdm(sorted(clip_dict.keys())):\n",
    "        numpy_data_path = clip_dict[video_id]\n",
    "        id2image_path = id2img_dict[video_id]\n",
    "        numpy_data = load_numpy(numpy_data_path)\n",
    "        id2image_data = reading_json_file(id2image_path)\n",
    "        id2image_data = convert_dict(begin_index, id2image_data)\n",
    "        global_embeddings.append(numpy_data)\n",
    "        global_id2image.update(id2image_data)\n",
    "        begin_index += len(id2image_data.items())\n",
    "global_embeddings = np.concatenate(global_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './dict'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "global_bin_save_path = os.path.join(save_dir, 'h14_xlm_laion5b.bin')\n",
    "global_id2img_save_path = os.path.join(save_dir, 'h14_xlm_laion5b.json')\n",
    "with open(global_id2img_save_path, 'w') as file:\n",
    "    json.dump(global_id2image, file, ensure_ascii=False, indent=4)\n",
    "save_bin_file(global_embeddings, bin_file=global_bin_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create ViT BLIP Bin File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File notebook này để tạo file bin cho các feature mô hình CLIP, BLIP\n",
    "# Muốn tạo folder cho mô hình nào thì cd đến folder chứa feature của mô hình đó trong dataset\n",
    "%cd D:/VNM-Multimodal-Video-Search/dataset/blip/blip2-vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blip_paths = parse_data_path(feature_dir='./features')\n",
    "all_id2img_paths = parse_data_path(feature_dir='./id2image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_embeddings = []\n",
    "global_id2image = {}\n",
    "begin_index = 0\n",
    "\n",
    "for blip_part in sorted(all_blip_paths.keys()):\n",
    "    blip_dict = all_blip_paths[blip_part]\n",
    "    id2img_dict = all_id2img_paths[blip_part]\n",
    "    for video_id in tqdm(sorted(blip_dict.keys())):\n",
    "        numpy_data_path = blip_dict[video_id]\n",
    "        id2image_path = id2img_dict[video_id]\n",
    "        numpy_data = load_numpy(numpy_data_path)\n",
    "        id2image_data = reading_json_file(id2image_path)\n",
    "        id2image_data = convert_dict(begin_index, id2image_data)\n",
    "        global_embeddings.append(numpy_data)\n",
    "        global_id2image.update(id2image_data)\n",
    "        begin_index += len(id2image_data.items())\n",
    "global_embeddings = np.concatenate(global_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './dict'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "global_bin_save_path = os.path.join(save_dir, 'blip_vit.bin')\n",
    "global_id2img_save_path = os.path.join(save_dir, 'blip_vit.json')\n",
    "with open(global_id2img_save_path, 'w') as file:\n",
    "    json.dump(global_id2image, file, ensure_ascii=False, indent=4)\n",
    "save_bin_file(global_embeddings, bin_file=global_bin_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create pretrained BLIP Bin File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File notebook này để tạo file bin cho các feature mô hình CLIP, BLIP\n",
    "# Muốn tạo folder cho mô hình nào thì cd đến folder chứa feature của mô hình đó trong dataset\n",
    "# File notebook này để tạo file bin cho các feature mô hình CLIP, BLIP\n",
    "# Muốn tạo folder cho mô hình nào thì cd đến folder chứa feature của mô hình đó trong dataset\n",
    "%cd D:/VNM-Multimodal-Video-Search/dataset/blip/blip2-pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blip_paths = parse_data_path(feature_dir='./features')\n",
    "all_id2img_paths = parse_data_path(feature_dir='./id2image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_embeddings = []\n",
    "global_id2image = {}\n",
    "begin_index = 0\n",
    "\n",
    "for blip_part in sorted(all_blip_paths.keys()):\n",
    "    blip_dict = all_blip_paths[blip_part]\n",
    "    id2img_dict = all_id2img_paths[blip_part]\n",
    "    for video_id in tqdm(sorted(blip_dict.keys())):\n",
    "        numpy_data_path = blip_dict[video_id]\n",
    "        id2image_path = id2img_dict[video_id]\n",
    "        numpy_data = load_numpy(numpy_data_path)\n",
    "        id2image_data = reading_json_file(id2image_path)\n",
    "        id2image_data = convert_dict(begin_index, id2image_data)\n",
    "        global_embeddings.append(numpy_data)\n",
    "        global_id2image.update(id2image_data)\n",
    "        begin_index += len(id2image_data.items())\n",
    "global_embeddings = np.concatenate(global_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './dict'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "global_bin_save_path = os.path.join(save_dir, 'blip_pretrain.bin')\n",
    "global_id2img_save_path = os.path.join(save_dir, 'blip_pretrain.json')\n",
    "with open(global_id2img_save_path, 'w') as file:\n",
    "    json.dump(global_id2image, file, ensure_ascii=False, indent=4)\n",
    "save_bin_file(global_embeddings, bin_file=global_bin_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create BEIT base model Bin File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File notebook này để tạo file bin cho các feature mô hình CLIP, BLIP\n",
    "# Muốn tạo folder cho mô hình nào thì cd đến folder chứa feature của mô hình đó trong dataset\n",
    "%cd D:/VNM-Multimodal-Video-Search/dataset/beit/base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blip_paths = parse_data_path(feature_dir='./features')\n",
    "all_id2img_paths = parse_data_path(feature_dir='./id2image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_embeddings = []\n",
    "global_id2image = {}\n",
    "begin_index = 0\n",
    "\n",
    "for blip_part in sorted(all_blip_paths.keys()):\n",
    "    blip_dict = all_blip_paths[blip_part]\n",
    "    id2img_dict = all_id2img_paths[blip_part]\n",
    "    for video_id in tqdm(sorted(blip_dict.keys())):\n",
    "        numpy_data_path = blip_dict[video_id]\n",
    "        id2image_path = id2img_dict[video_id]\n",
    "        numpy_data = load_numpy(numpy_data_path)\n",
    "        id2image_data = reading_json_file(id2image_path)\n",
    "        id2image_data = convert_dict(begin_index, id2image_data)\n",
    "        global_embeddings.append(numpy_data)\n",
    "        global_id2image.update(id2image_data)\n",
    "        begin_index += len(id2image_data.items())\n",
    "global_embeddings = np.concatenate(global_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './dict'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "global_bin_save_path = os.path.join(save_dir, 'base_beit.bin')\n",
    "global_id2img_save_path = os.path.join(save_dir, 'base_beit.json')\n",
    "with open(global_id2img_save_path, 'w') as file:\n",
    "    json.dump(global_id2image, file, ensure_ascii=False, indent=4)\n",
    "save_bin_file(global_embeddings, bin_file=global_bin_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create BEIT large model Bin File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File notebook này để tạo file bin cho các feature mô hình CLIP, BLIP\n",
    "# Muốn tạo folder cho mô hình nào thì cd đến folder chứa feature của mô hình đó trong dataset\n",
    "%cd D:/VNM-Multimodal-Video-Search/dataset/beit/large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blip_paths = parse_data_path(feature_dir='./features')\n",
    "all_id2img_paths = parse_data_path(feature_dir='./id2image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_embeddings = []\n",
    "global_id2image = {}\n",
    "begin_index = 0\n",
    "\n",
    "for blip_part in sorted(all_blip_paths.keys()):\n",
    "    blip_dict = all_blip_paths[blip_part]\n",
    "    id2img_dict = all_id2img_paths[blip_part]\n",
    "    for video_id in tqdm(sorted(blip_dict.keys())):\n",
    "        numpy_data_path = blip_dict[video_id]\n",
    "        id2image_path = id2img_dict[video_id]\n",
    "        numpy_data = load_numpy(numpy_data_path)\n",
    "        id2image_data = reading_json_file(id2image_path)\n",
    "        id2image_data = convert_dict(begin_index, id2image_data)\n",
    "        global_embeddings.append(numpy_data)\n",
    "        global_id2image.update(id2image_data)\n",
    "        begin_index += len(id2image_data.items())\n",
    "global_embeddings = np.concatenate(global_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './dict'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "global_bin_save_path = os.path.join(save_dir, 'large_beit.bin')\n",
    "global_id2img_save_path = os.path.join(save_dir, 'large_beit.json')\n",
    "with open(global_id2img_save_path, 'w') as file:\n",
    "    json.dump(global_id2image, file, ensure_ascii=False, indent=4)\n",
    "save_bin_file(global_embeddings, bin_file=global_bin_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aic2024-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
