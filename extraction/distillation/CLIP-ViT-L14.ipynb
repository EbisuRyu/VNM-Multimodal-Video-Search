{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LONG\\anaconda3\\envs\\aic2024-env-new\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import open_clip\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\AIC2024\\dataset\n"
     ]
    }
   ],
   "source": [
    "%cd D:/AIC2024/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parsing Data Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_path(feature_dir='./keyframe'):\n",
    "    all_feature_paths = dict()\n",
    "    for feature_part in sorted(os.listdir(feature_dir)):\n",
    "        all_feature_paths[feature_part] = dict()\n",
    "    for feature_part in sorted(all_feature_paths.keys()):\n",
    "        feature_part_path = f'{feature_dir}/{feature_part}'\n",
    "        feature_paths = sorted(os.listdir(feature_part_path))\n",
    "        feature_ids = [feature_path.split('.')[0] for feature_path in feature_paths]\n",
    "        for feature_id, feature_path in zip(feature_ids, feature_paths):\n",
    "            feature_path_full = f'{feature_part_path}/{feature_path}'\n",
    "            all_feature_paths[feature_part][feature_id] = feature_path_full\n",
    "    return all_feature_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_video_paths = parse_data_path(feature_dir='./keyframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **CLIP ViT-L/14 Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LONG\\anaconda3\\envs\\aic2024-env-new\\lib\\site-packages\\open_clip\\factory.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "model = 'ViT-L-14'\n",
    "pretrained = 'laion2b_s32b_b82k'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(model, device=device, pretrained=pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images(image_paths, batch_size):\n",
    "    id2image_fps = {}\n",
    "    video_features, images = [], []\n",
    "    for id, image_path in enumerate(image_paths):\n",
    "        id2image_fps[id] = image_path\n",
    "        image = preprocess(Image.open(image_path)).unsqueeze(0)\n",
    "        images.append(image)\n",
    "\n",
    "    images = torch.cat(images, dim=0).to(device)\n",
    "    with torch.no_grad():\n",
    "        for start_index in range(0, images.shape[0], batch_size):\n",
    "            image_features = model.encode_image(images[start_index:start_index+batch_size])\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            for index in range(image_features.shape[0]):\n",
    "                video_features.append(image_features[index].cpu().numpy().astype(np.float32).flatten())\n",
    "    return id2image_fps, video_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Keyframe Distillation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector_a, vector_b):\n",
    "    cosine_score = np.dot(vector_a, vector_b) / (np.linalg.norm(vector_a) * np.linalg.norm(vector_b))\n",
    "    return cosine_score\n",
    "\n",
    "def write_json_file(content_list, save_json_file_path):\n",
    "    with open(save_json_file_path, 'w') as file:\n",
    "        json.dump(content_list, file)\n",
    "        \n",
    "def sorted_by_id(keyframe_paths):\n",
    "    id_path_keyframes = []\n",
    "    for keyframe_path in keyframe_paths:\n",
    "        keyframe_filename = keyframe_path.split('/')[-1]\n",
    "        keyframe_id = int(keyframe_filename.split('.')[0])\n",
    "        id_path_keyframes.append((keyframe_id, keyframe_path))\n",
    "    sorted_id_path_keyframes = sorted(id_path_keyframes, key=lambda id_path: id_path[0])\n",
    "    return [id_path[1] for id_path in sorted_id_path_keyframes]\n",
    "\n",
    "def keyframe_distillation(video_features, id2image_fps, compare_length=2, threshold=0.9):\n",
    "    distilled_ids = []\n",
    "    distilled_features = []\n",
    "    for feature_id, feature_vector in enumerate(video_features):\n",
    "        adding_condition = True\n",
    "        compare_features = distilled_features[-compare_length:]\n",
    "        for compare_vetor in compare_features:\n",
    "            cosine_score = cosine_similarity(compare_vetor, feature_vector)\n",
    "            if cosine_score > threshold:\n",
    "                adding_condition = False\n",
    "                break\n",
    "        if adding_condition:\n",
    "            distilled_ids.append(feature_id)\n",
    "            distilled_features.append(feature_vector)\n",
    "    distilled_image_paths = [id2image_fps[distilled_id] for distilled_id in distilled_ids]\n",
    "    return distilled_features, distilled_image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_save_dir='./distillation'\n",
    "feature_save_dir = './clip/clip-vit-l14-laion2b/features'\n",
    "id2image_save_dir = './clip/clip-vit-l14-laion2b/id2image'\n",
    "if not os.path.exists(distillation_save_dir):\n",
    "    os.makedirs(distillation_save_dir)\n",
    "if not os.path.exists(feature_save_dir):\n",
    "    os.makedirs(feature_save_dir)\n",
    "if not os.path.exists(id2image_save_dir):\n",
    "    os.makedirs(id2image_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distilling Part L01: 100%|██████████| 31/31 [16:46:46<00:00, 1948.59s/it]  \n",
      "Distilling Part L02:   0%|          | 0/31 [03:06<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for video_part, video_path_dict in all_video_paths.items():\n",
    "    video_ids = video_path_dict.keys()\n",
    "    for video_id in tqdm(video_ids, desc=f'Distilling Part {video_part}'):\n",
    "        \n",
    "        video_id_path = video_path_dict[video_id]\n",
    "        keyframe_image_paths = [video_id_path + '/' + keyframe_image_path for keyframe_image_path in os.listdir(video_id_path)]\n",
    "        sorted_keyframe_image_paths = sorted_by_id(keyframe_image_paths)\n",
    "        id2image_fps, video_features = encode_images(sorted_keyframe_image_paths, batch_size)\n",
    "\n",
    "        distilled_features, distilled_keyframe_image_paths = keyframe_distillation(\n",
    "            video_features=video_features,\n",
    "            id2image_fps=id2image_fps,\n",
    "            compare_length=2,\n",
    "            threshold=0.9\n",
    "        )\n",
    "        \n",
    "        distilled_id2image_fps = {id:keyframe_path for id, keyframe_path in enumerate(distilled_keyframe_image_paths)}\n",
    "        os.makedirs(f'{feature_save_dir}/{video_part}', exist_ok=True)\n",
    "        np.save(f'{feature_save_dir}/{video_part}/{video_id}.npy', video_features)\n",
    "\n",
    "        os.makedirs(f'{id2image_save_dir}/{video_part}', exist_ok=True)\n",
    "        with open(f'{id2image_save_dir}/{video_part}/{video_id}.json', 'w') as f:\n",
    "            f.write(json.dumps(distilled_id2image_fps))\n",
    "        \n",
    "        save_part_dir = f'{distillation_save_dir}/{video_part}'\n",
    "        os.makedirs(save_part_dir, exist_ok=True)\n",
    "        save_json_file_path = save_part_dir + '/' + f'{video_id}.json'\n",
    "        write_json_file(distilled_keyframe_image_paths, save_json_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aic2024-env-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
